{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 : GPU Check\n",
    "\n",
    "This is a simple test to see if the GPU is available and working correctly.\n",
    "\n",
    "- https://stackoverflow.com/questions/76581229/is-it-possible-to-check-if-gpu-is-available-without-using-deep-learning-packages\n",
    "- https://docs.mlrun.org/en/v1.7.2/runtimes/configuring-job-resources.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the API server URL\n",
    "mlrun.get_run_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base project name\n",
    "project_name = \"mlrun-demo\"\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(\n",
    "    name=project_name, \n",
    "    context=\"./\",\n",
    "    user_project=True)\n",
    "\n",
    "# Display the current project name\n",
    "project_name = project.metadata.name\n",
    "print(f'Full project name: {project_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GPU Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 02_get_gpu_info.py\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "def get_gpu_info(context):    \n",
    "    gpus = GPUtil.getGPUs()\n",
    "    gpu_info = []\n",
    "    for gpu in gpus:\n",
    "        gpu_info.append({\n",
    "            'id': gpu.id,\n",
    "            'name': gpu.name,\n",
    "            'load': gpu.load,\n",
    "            'memory_total': gpu.memoryTotal,\n",
    "            'memory_free': gpu.memoryFree,\n",
    "            'memory_used': gpu.memoryUsed,\n",
    "        })\n",
    "\n",
    "    context.logger.info(f\"GPU Info: {gpu_info}\")\n",
    "    return gpu_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_gpu_check = project.set_function(\n",
    "    func=\"02_get_gpu_info.py\",\n",
    "    name=\"gpu-check\",\n",
    "    tag=\"latest\",\n",
    "    kind=\"job\",\n",
    "    image=\"mlrun/mlrun\",\n",
    "    handler=\"get_gpu_info\",\n",
    "    requirements=[\"GPUtil==1.4.0\"])\n",
    "\n",
    "# Then set the GPU resources on the function's spec\n",
    "fn_gpu_check.spec.resources = {\n",
    "    \"limits\": {\"nvidia.com/gpu\": 1},\n",
    "    \"requests\": {\"nvidia.com/gpu\": 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function locally\n",
    "fn_gpu_check.run(\n",
    "    local=False,\n",
    "    handler=\"get_gpu_info\",\n",
    "    auto_build=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-mlrun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
