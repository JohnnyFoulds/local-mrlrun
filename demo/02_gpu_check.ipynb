{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 : GPU Check\n",
    "\n",
    "This is a simple test to see if the GPU is available and working correctly.\n",
    "\n",
    "- https://stackoverflow.com/questions/76581229/is-it-possible-to-check-if-gpu-is-available-without-using-deep-learning-packages\n",
    "- https://docs.mlrun.org/en/v1.7.2/runtimes/configuring-job-resources.html\n",
    "- https://docs.k3s.io/advanced#nvidia-container-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the API server URL\n",
    "mlrun.get_run_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base project name\n",
    "project_name = \"mlrun-demo\"\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(\n",
    "    name=project_name, \n",
    "    context=\"./\",\n",
    "    user_project=True)\n",
    "\n",
    "# Display the current project name\n",
    "project_name = project.metadata.name\n",
    "print(f'Full project name: {project_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GPU Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 02_get_gpu_info.py\n",
    "\n",
    "import GPUtil\n",
    "import subprocess\n",
    "\n",
    "def get_gpu_info(context):    \n",
    "    gpus = GPUtil.getGPUs()\n",
    "    gpu_info = []\n",
    "    for gpu in gpus:\n",
    "        gpu_info.append({\n",
    "            'id': gpu.id,\n",
    "            'name': gpu.name,\n",
    "            'load': gpu.load,\n",
    "            'memory_total': gpu.memoryTotal,\n",
    "            'memory_free': gpu.memoryFree,\n",
    "            'memory_used': gpu.memoryUsed,\n",
    "        })\n",
    "\n",
    "    print(f\"GPU Info v4: {gpu_info}\")\n",
    "    context.logger.info(f\"GPU Info: {gpu_info}\")\n",
    "\n",
    "    # execute the nvidia-smi command on the cli to get detailed GPU info\n",
    "    try:\n",
    "        nvidia_smi_output = subprocess.check_output(['nvidia-smi'], universal_newlines=True)\n",
    "        print(\"NVIDIA-SMI Output:\")\n",
    "        print(nvidia_smi_output)\n",
    "        context.logger.info(f\"NVIDIA-SMI Output:\\n{nvidia_smi_output}\")\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error running nvidia-smi: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        context.logger.warning(error_msg)\n",
    "    \n",
    "    return gpu_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = \"mlrun/mlrun-gpu:1.9.1-py39\"\n",
    "#image =  \"dragon:30500/mlrun/mlrun-gpu:1.9.1-py39\"\n",
    "#image =  \"mlrun/mlrun-gpu:1.7.2\"\n",
    "image =  \"mlrun/mlrun:1.7.2\"\n",
    "\n",
    "fn_gpu_check = project.set_function(\n",
    "    func=\"02_get_gpu_info.py\",\n",
    "    name=\"gpu-check\",\n",
    "    tag=\"latest\",\n",
    "    kind=\"job\",\n",
    "    image=image,\n",
    "    handler=\"get_gpu_info\",\n",
    "    requirements=[\"GPUtil==1.4.0\"])\n",
    "\n",
    "# Then set the GPU resources on the function's spec\n",
    "fn_gpu_check.with_limits(mem=\"2G\", cpu=2, gpus=1)  # upper bound\n",
    "\n",
    "# build the function\n",
    "project.build_function(function='gpu-check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function locally\n",
    "fn_gpu_check.run(\n",
    "    local=False,\n",
    "    handler=\"get_gpu_info\",\n",
    "    auto_build=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh the function from the saved .py file (this is instant)\n",
    "project.set_function(func=\"02_get_gpu_info.py\", name=\"gpu-check\")\n",
    "\n",
    "# run the function again [you can modify the py file and set the function again = this will not rebuild the entire thing] \n",
    "project.run_function(\n",
    "    function='gpu-check',\n",
    "    handler='get_gpu_info'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-mlrun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
